{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd033a3111211be4281f3a8c4a9b25563b8d253df502c7e31f5318895c1792a97cb",
   "display_name": "Python 3.8.8 64-bit ('py38': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1. Data Loader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../result_file/preprocess_results/\"\n",
    "submission_dir = \"../../../kaggle_data/creditcard_overdue/open/\"\n",
    "\n",
    "train_bin10 = pd.read_csv(os.path.join(data_dir, \"train_income_bin10.csv\"))\n",
    "\n",
    "X_test = pd.read_csv(os.path.join(data_dir, \"test_income_bin10.csv\"))\n",
    "\n",
    "submission = pd.read_csv(os.path.join(submission_dir, \"sample_submission.csv\"))"
   ]
  },
  {
   "source": [
    "# 2. Data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_bin10.drop(['credit'], axis=1)\n",
    "y_train = train_bin10['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "source": [
    "# 3. Training : Stacking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3-1. Tuning each model's hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "source": [
    "### 3-1-1. Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.1s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=   9.9s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=   9.9s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=   9.9s\n",
      "[CV] END criterion=gini, max_depth=9, n_estimators=800, random_state=42; total time=  10.0s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  20.3s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  20.4s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  20.1s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  19.0s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  20.3s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  19.1s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  19.5s\n",
      "[CV] END criterion=gini, max_depth=21, n_estimators=800, random_state=42; total time=  19.2s\n",
      "Best Score :  -0.7275500068278175\n",
      "Best params : \n",
      " {'criterion': 'gini', 'max_depth': 21, 'n_estimators': 800, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest_param_grid = {\n",
    "    \"max_depth\" : [21],\n",
    "    \"n_estimators\" : [900],\n",
    "    \"criterion\" : [\"gini\"],\n",
    "    \"random_state\" : [42]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    forest, forest_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_forest = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best params : \\n\", gs.best_params_)"
   ]
  },
  {
   "source": [
    "#### 3-1-1-1. Random Forest (without GridSearchCV)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "    max_depth=21,\n",
    "    n_estimators=900,\n",
    "    criterion=\"gini\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_forest = forest.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "### 3-1-2. LightGBM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.1s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.7s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.7s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.9s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.0s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.9s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.1s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   8.0s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.1s\n",
      "[CV] END learning_rate=0.01, max_depth=21, n_estimators=2500, random_state=42; total time=   7.1s\n",
      "Best Score :  -0.7550573109370209\n",
      "Best Params : \n",
      " {'learning_rate': 0.01, 'max_depth': 21, 'n_estimators': 2500, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "\n",
    "lgb_param_grid = {\n",
    "    \"n_estimators\" : [2500],\n",
    "    \"learning_rate\" : [0.01],\n",
    "    \"max_depth\" : [21],\n",
    "    \"random_state\" : [42]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    lgb, lgb_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_lgb = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best Params : \\n\", gs.best_params_)"
   ]
  },
  {
   "source": [
    "#### 3-1-2-1. LightGBM (without GridSearchCV)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=2500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=21,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_lgb = lgb.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "### 3-1-3. XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.8min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2700, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.1min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.1min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=9, n_estimators=2900, reg_lambda=1.7256912198205319, seed=42, use_label_encoder=False; total time= 2.1min\n",
      "Best Score :  -0.7490923308954026\n",
      "Best params : \n",
      " {'eval_metric': 'mlogloss', 'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 2700, 'reg_lambda': 1.7256912198205319, 'seed': 42, 'use_label_encoder': False}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\" : [2500],\n",
    "    \"eval_metric\" : [\"mlogloss\"],\n",
    "    \"learning_rate\" : [0.01],\n",
    "    \"max_depth\" : [9],\n",
    "    \"use_label_encoder\" : [False],\n",
    "    \"reg_lambda\" : [1.7256912198205319],\n",
    "    \"seed\" : [42]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    xgb, xgb_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best params : \\n\", gs.best_params_)"
   ]
  },
  {
   "source": [
    "#### 3-1-3-1. XGBoost (without GridSearchCV)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=2500,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    learning_rate=0.01,\n",
    "    max_depth=9,\n",
    "    use_label_encoder=False,\n",
    "    reg_lambda=1.7256912198205319,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_xgb = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "### 3-1-4. CatBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "m 31s\tremaining: 4.38s\n",
      "7634:\tlearn: 0.5183615\ttotal: 1m 31s\tremaining: 4.37s\n",
      "7635:\tlearn: 0.5183450\ttotal: 1m 31s\tremaining: 4.36s\n",
      "7636:\tlearn: 0.5183006\ttotal: 1m 31s\tremaining: 4.34s\n",
      "7637:\tlearn: 0.5182788\ttotal: 1m 31s\tremaining: 4.33s\n",
      "7638:\tlearn: 0.5182641\ttotal: 1m 31s\tremaining: 4.32s\n",
      "7639:\tlearn: 0.5182461\ttotal: 1m 31s\tremaining: 4.31s\n",
      "7640:\tlearn: 0.5182258\ttotal: 1m 31s\tremaining: 4.3s\n",
      "7641:\tlearn: 0.5182019\ttotal: 1m 31s\tremaining: 4.28s\n",
      "7642:\tlearn: 0.5181807\ttotal: 1m 31s\tremaining: 4.27s\n",
      "7643:\tlearn: 0.5181739\ttotal: 1m 31s\tremaining: 4.26s\n",
      "7644:\tlearn: 0.5181528\ttotal: 1m 31s\tremaining: 4.25s\n",
      "7645:\tlearn: 0.5181457\ttotal: 1m 31s\tremaining: 4.24s\n",
      "7646:\tlearn: 0.5181137\ttotal: 1m 31s\tremaining: 4.22s\n",
      "7647:\tlearn: 0.5180998\ttotal: 1m 31s\tremaining: 4.21s\n",
      "7648:\tlearn: 0.5180871\ttotal: 1m 31s\tremaining: 4.2s\n",
      "7649:\tlearn: 0.5180685\ttotal: 1m 31s\tremaining: 4.19s\n",
      "7650:\tlearn: 0.5180411\ttotal: 1m 31s\tremaining: 4.18s\n",
      "7651:\tlearn: 0.5180130\ttotal: 1m 31s\tremaining: 4.16s\n",
      "7652:\tlearn: 0.5179778\ttotal: 1m 31s\tremaining: 4.15s\n",
      "7653:\tlearn: 0.5179536\ttotal: 1m 31s\tremaining: 4.14s\n",
      "7654:\tlearn: 0.5179228\ttotal: 1m 31s\tremaining: 4.13s\n",
      "7655:\tlearn: 0.5179093\ttotal: 1m 31s\tremaining: 4.12s\n",
      "7656:\tlearn: 0.5178926\ttotal: 1m 31s\tremaining: 4.11s\n",
      "7657:\tlearn: 0.5178772\ttotal: 1m 31s\tremaining: 4.09s\n",
      "7658:\tlearn: 0.5178656\ttotal: 1m 31s\tremaining: 4.08s\n",
      "7659:\tlearn: 0.5178597\ttotal: 1m 31s\tremaining: 4.07s\n",
      "7660:\tlearn: 0.5178211\ttotal: 1m 31s\tremaining: 4.06s\n",
      "7661:\tlearn: 0.5178066\ttotal: 1m 31s\tremaining: 4.04s\n",
      "7662:\tlearn: 0.5177903\ttotal: 1m 31s\tremaining: 4.03s\n",
      "7663:\tlearn: 0.5177708\ttotal: 1m 31s\tremaining: 4.02s\n",
      "7664:\tlearn: 0.5177609\ttotal: 1m 31s\tremaining: 4.01s\n",
      "7665:\tlearn: 0.5177437\ttotal: 1m 31s\tremaining: 4s\n",
      "7666:\tlearn: 0.5177199\ttotal: 1m 31s\tremaining: 3.98s\n",
      "7667:\tlearn: 0.5176997\ttotal: 1m 31s\tremaining: 3.97s\n",
      "7668:\tlearn: 0.5176677\ttotal: 1m 31s\tremaining: 3.96s\n",
      "7669:\tlearn: 0.5176513\ttotal: 1m 31s\tremaining: 3.95s\n",
      "7670:\tlearn: 0.5176397\ttotal: 1m 31s\tremaining: 3.94s\n",
      "7671:\tlearn: 0.5176144\ttotal: 1m 31s\tremaining: 3.92s\n",
      "7672:\tlearn: 0.5175931\ttotal: 1m 31s\tremaining: 3.91s\n",
      "7673:\tlearn: 0.5175864\ttotal: 1m 31s\tremaining: 3.9s\n",
      "7674:\tlearn: 0.5175654\ttotal: 1m 31s\tremaining: 3.89s\n",
      "7675:\tlearn: 0.5175382\ttotal: 1m 31s\tremaining: 3.88s\n",
      "7676:\tlearn: 0.5175198\ttotal: 1m 31s\tremaining: 3.87s\n",
      "7677:\tlearn: 0.5174991\ttotal: 1m 31s\tremaining: 3.85s\n",
      "7678:\tlearn: 0.5174769\ttotal: 1m 31s\tremaining: 3.84s\n",
      "7679:\tlearn: 0.5174492\ttotal: 1m 31s\tremaining: 3.83s\n",
      "7680:\tlearn: 0.5174174\ttotal: 1m 31s\tremaining: 3.82s\n",
      "7681:\tlearn: 0.5173977\ttotal: 1m 31s\tremaining: 3.81s\n",
      "7682:\tlearn: 0.5173787\ttotal: 1m 31s\tremaining: 3.79s\n",
      "7683:\tlearn: 0.5173334\ttotal: 1m 31s\tremaining: 3.78s\n",
      "7684:\tlearn: 0.5173068\ttotal: 1m 31s\tremaining: 3.77s\n",
      "7685:\tlearn: 0.5172885\ttotal: 1m 31s\tremaining: 3.76s\n",
      "7686:\tlearn: 0.5172712\ttotal: 1m 31s\tremaining: 3.75s\n",
      "7687:\tlearn: 0.5172391\ttotal: 1m 32s\tremaining: 3.73s\n",
      "7688:\tlearn: 0.5172238\ttotal: 1m 32s\tremaining: 3.72s\n",
      "7689:\tlearn: 0.5172074\ttotal: 1m 32s\tremaining: 3.71s\n",
      "7690:\tlearn: 0.5171654\ttotal: 1m 32s\tremaining: 3.7s\n",
      "7691:\tlearn: 0.5171528\ttotal: 1m 32s\tremaining: 3.69s\n",
      "7692:\tlearn: 0.5171107\ttotal: 1m 32s\tremaining: 3.67s\n",
      "7693:\tlearn: 0.5170859\ttotal: 1m 32s\tremaining: 3.66s\n",
      "7694:\tlearn: 0.5170501\ttotal: 1m 32s\tremaining: 3.65s\n",
      "7695:\tlearn: 0.5170311\ttotal: 1m 32s\tremaining: 3.64s\n",
      "7696:\tlearn: 0.5170103\ttotal: 1m 32s\tremaining: 3.63s\n",
      "7697:\tlearn: 0.5169776\ttotal: 1m 32s\tremaining: 3.61s\n",
      "7698:\tlearn: 0.5169419\ttotal: 1m 32s\tremaining: 3.6s\n",
      "7699:\tlearn: 0.5169357\ttotal: 1m 32s\tremaining: 3.59s\n",
      "7700:\tlearn: 0.5169167\ttotal: 1m 32s\tremaining: 3.58s\n",
      "7701:\tlearn: 0.5168916\ttotal: 1m 32s\tremaining: 3.57s\n",
      "7702:\tlearn: 0.5168700\ttotal: 1m 32s\tremaining: 3.55s\n",
      "7703:\tlearn: 0.5168475\ttotal: 1m 32s\tremaining: 3.54s\n",
      "7704:\tlearn: 0.5168188\ttotal: 1m 32s\tremaining: 3.53s\n",
      "7705:\tlearn: 0.5167947\ttotal: 1m 32s\tremaining: 3.52s\n",
      "7706:\tlearn: 0.5167696\ttotal: 1m 32s\tremaining: 3.51s\n",
      "7707:\tlearn: 0.5167370\ttotal: 1m 32s\tremaining: 3.5s\n",
      "7708:\tlearn: 0.5167134\ttotal: 1m 32s\tremaining: 3.48s\n",
      "7709:\tlearn: 0.5166994\ttotal: 1m 32s\tremaining: 3.47s\n",
      "7710:\tlearn: 0.5166779\ttotal: 1m 32s\tremaining: 3.46s\n",
      "7711:\tlearn: 0.5166575\ttotal: 1m 32s\tremaining: 3.45s\n",
      "7712:\tlearn: 0.5166275\ttotal: 1m 32s\tremaining: 3.44s\n",
      "7713:\tlearn: 0.5166087\ttotal: 1m 32s\tremaining: 3.42s\n",
      "7714:\tlearn: 0.5165929\ttotal: 1m 32s\tremaining: 3.41s\n",
      "7715:\tlearn: 0.5165798\ttotal: 1m 32s\tremaining: 3.4s\n",
      "7716:\tlearn: 0.5165587\ttotal: 1m 32s\tremaining: 3.39s\n",
      "7717:\tlearn: 0.5165280\ttotal: 1m 32s\tremaining: 3.38s\n",
      "7718:\tlearn: 0.5165145\ttotal: 1m 32s\tremaining: 3.36s\n",
      "7719:\tlearn: 0.5164846\ttotal: 1m 32s\tremaining: 3.35s\n",
      "7720:\tlearn: 0.5164429\ttotal: 1m 32s\tremaining: 3.34s\n",
      "7721:\tlearn: 0.5164295\ttotal: 1m 32s\tremaining: 3.33s\n",
      "7722:\tlearn: 0.5163954\ttotal: 1m 32s\tremaining: 3.31s\n",
      "7723:\tlearn: 0.5163892\ttotal: 1m 32s\tremaining: 3.3s\n",
      "7724:\tlearn: 0.5163542\ttotal: 1m 32s\tremaining: 3.29s\n",
      "7725:\tlearn: 0.5163229\ttotal: 1m 32s\tremaining: 3.28s\n",
      "7726:\tlearn: 0.5162941\ttotal: 1m 32s\tremaining: 3.27s\n",
      "7727:\tlearn: 0.5162764\ttotal: 1m 32s\tremaining: 3.26s\n",
      "7728:\tlearn: 0.5162609\ttotal: 1m 32s\tremaining: 3.24s\n",
      "7729:\tlearn: 0.5162330\ttotal: 1m 32s\tremaining: 3.23s\n",
      "7730:\tlearn: 0.5162137\ttotal: 1m 32s\tremaining: 3.22s\n",
      "7731:\tlearn: 0.5161917\ttotal: 1m 32s\tremaining: 3.21s\n",
      "7732:\tlearn: 0.5161768\ttotal: 1m 32s\tremaining: 3.2s\n",
      "7733:\tlearn: 0.5161423\ttotal: 1m 32s\tremaining: 3.18s\n",
      "7734:\tlearn: 0.5161244\ttotal: 1m 32s\tremaining: 3.17s\n",
      "7735:\tlearn: 0.5161168\ttotal: 1m 32s\tremaining: 3.16s\n",
      "7736:\tlearn: 0.5160925\ttotal: 1m 32s\tremaining: 3.15s\n",
      "7737:\tlearn: 0.5160562\ttotal: 1m 32s\tremaining: 3.14s\n",
      "7738:\tlearn: 0.5160374\ttotal: 1m 32s\tremaining: 3.12s\n",
      "7739:\tlearn: 0.5160084\ttotal: 1m 32s\tremaining: 3.11s\n",
      "7740:\tlearn: 0.5159929\ttotal: 1m 32s\tremaining: 3.1s\n",
      "7741:\tlearn: 0.5159598\ttotal: 1m 32s\tremaining: 3.09s\n",
      "7742:\tlearn: 0.5159219\ttotal: 1m 32s\tremaining: 3.08s\n",
      "7743:\tlearn: 0.5159097\ttotal: 1m 32s\tremaining: 3.06s\n",
      "7744:\tlearn: 0.5158839\ttotal: 1m 32s\tremaining: 3.05s\n",
      "7745:\tlearn: 0.5158712\ttotal: 1m 32s\tremaining: 3.04s\n",
      "7746:\tlearn: 0.5158483\ttotal: 1m 32s\tremaining: 3.03s\n",
      "7747:\tlearn: 0.5158184\ttotal: 1m 32s\tremaining: 3.02s\n",
      "7748:\tlearn: 0.5157811\ttotal: 1m 32s\tremaining: 3s\n",
      "7749:\tlearn: 0.5157558\ttotal: 1m 32s\tremaining: 2.99s\n",
      "7750:\tlearn: 0.5157230\ttotal: 1m 32s\tremaining: 2.98s\n",
      "7751:\tlearn: 0.5157033\ttotal: 1m 32s\tremaining: 2.97s\n",
      "7752:\tlearn: 0.5156721\ttotal: 1m 32s\tremaining: 2.96s\n",
      "7753:\tlearn: 0.5156465\ttotal: 1m 32s\tremaining: 2.94s\n",
      "7754:\tlearn: 0.5156314\ttotal: 1m 32s\tremaining: 2.93s\n",
      "7755:\tlearn: 0.5155883\ttotal: 1m 32s\tremaining: 2.92s\n",
      "7756:\tlearn: 0.5155705\ttotal: 1m 32s\tremaining: 2.91s\n",
      "7757:\tlearn: 0.5155495\ttotal: 1m 32s\tremaining: 2.9s\n",
      "7758:\tlearn: 0.5155338\ttotal: 1m 32s\tremaining: 2.88s\n",
      "7759:\tlearn: 0.5155162\ttotal: 1m 32s\tremaining: 2.87s\n",
      "7760:\tlearn: 0.5154832\ttotal: 1m 32s\tremaining: 2.86s\n",
      "7761:\tlearn: 0.5154663\ttotal: 1m 32s\tremaining: 2.85s\n",
      "7762:\tlearn: 0.5154438\ttotal: 1m 32s\tremaining: 2.84s\n",
      "7763:\tlearn: 0.5154303\ttotal: 1m 32s\tremaining: 2.83s\n",
      "7764:\tlearn: 0.5154098\ttotal: 1m 32s\tremaining: 2.81s\n",
      "7765:\tlearn: 0.5153800\ttotal: 1m 32s\tremaining: 2.8s\n",
      "7766:\tlearn: 0.5153583\ttotal: 1m 32s\tremaining: 2.79s\n",
      "7767:\tlearn: 0.5153389\ttotal: 1m 32s\tremaining: 2.78s\n",
      "7768:\tlearn: 0.5153146\ttotal: 1m 33s\tremaining: 2.77s\n",
      "7769:\tlearn: 0.5152877\ttotal: 1m 33s\tremaining: 2.75s\n",
      "7770:\tlearn: 0.5152781\ttotal: 1m 33s\tremaining: 2.74s\n",
      "7771:\tlearn: 0.5152490\ttotal: 1m 33s\tremaining: 2.73s\n",
      "7772:\tlearn: 0.5152306\ttotal: 1m 33s\tremaining: 2.72s\n",
      "7773:\tlearn: 0.5152184\ttotal: 1m 33s\tremaining: 2.71s\n",
      "7774:\tlearn: 0.5151963\ttotal: 1m 33s\tremaining: 2.69s\n",
      "7775:\tlearn: 0.5151708\ttotal: 1m 33s\tremaining: 2.68s\n",
      "7776:\tlearn: 0.5151543\ttotal: 1m 33s\tremaining: 2.67s\n",
      "7777:\tlearn: 0.5151284\ttotal: 1m 33s\tremaining: 2.66s\n",
      "7778:\tlearn: 0.5150952\ttotal: 1m 33s\tremaining: 2.65s\n",
      "7779:\tlearn: 0.5150726\ttotal: 1m 33s\tremaining: 2.63s\n",
      "7780:\tlearn: 0.5150571\ttotal: 1m 33s\tremaining: 2.62s\n",
      "7781:\tlearn: 0.5150463\ttotal: 1m 33s\tremaining: 2.61s\n",
      "7782:\tlearn: 0.5150255\ttotal: 1m 33s\tremaining: 2.6s\n",
      "7783:\tlearn: 0.5150011\ttotal: 1m 33s\tremaining: 2.58s\n",
      "7784:\tlearn: 0.5149740\ttotal: 1m 33s\tremaining: 2.57s\n",
      "7785:\tlearn: 0.5149405\ttotal: 1m 33s\tremaining: 2.56s\n",
      "7786:\tlearn: 0.5149148\ttotal: 1m 33s\tremaining: 2.55s\n",
      "7787:\tlearn: 0.5148836\ttotal: 1m 33s\tremaining: 2.54s\n",
      "7788:\tlearn: 0.5148570\ttotal: 1m 33s\tremaining: 2.52s\n",
      "7789:\tlearn: 0.5148174\ttotal: 1m 33s\tremaining: 2.51s\n",
      "7790:\tlearn: 0.5147846\ttotal: 1m 33s\tremaining: 2.5s\n",
      "7791:\tlearn: 0.5147708\ttotal: 1m 33s\tremaining: 2.49s\n",
      "7792:\tlearn: 0.5147281\ttotal: 1m 33s\tremaining: 2.48s\n",
      "7793:\tlearn: 0.5147017\ttotal: 1m 33s\tremaining: 2.47s\n",
      "7794:\tlearn: 0.5146873\ttotal: 1m 33s\tremaining: 2.45s\n",
      "7795:\tlearn: 0.5146466\ttotal: 1m 33s\tremaining: 2.44s\n",
      "7796:\tlearn: 0.5146243\ttotal: 1m 33s\tremaining: 2.43s\n",
      "7797:\tlearn: 0.5146099\ttotal: 1m 33s\tremaining: 2.42s\n",
      "7798:\tlearn: 0.5145867\ttotal: 1m 33s\tremaining: 2.41s\n",
      "7799:\tlearn: 0.5145617\ttotal: 1m 33s\tremaining: 2.39s\n",
      "7800:\tlearn: 0.5145499\ttotal: 1m 33s\tremaining: 2.38s\n",
      "7801:\tlearn: 0.5145408\ttotal: 1m 33s\tremaining: 2.37s\n",
      "7802:\tlearn: 0.5145278\ttotal: 1m 33s\tremaining: 2.36s\n",
      "7803:\tlearn: 0.5144988\ttotal: 1m 33s\tremaining: 2.35s\n",
      "7804:\tlearn: 0.5144874\ttotal: 1m 33s\tremaining: 2.33s\n",
      "7805:\tlearn: 0.5144786\ttotal: 1m 33s\tremaining: 2.32s\n",
      "7806:\tlearn: 0.5144516\ttotal: 1m 33s\tremaining: 2.31s\n",
      "7807:\tlearn: 0.5144379\ttotal: 1m 33s\tremaining: 2.3s\n",
      "7808:\tlearn: 0.5144106\ttotal: 1m 33s\tremaining: 2.29s\n",
      "7809:\tlearn: 0.5143895\ttotal: 1m 33s\tremaining: 2.27s\n",
      "7810:\tlearn: 0.5143658\ttotal: 1m 33s\tremaining: 2.26s\n",
      "7811:\tlearn: 0.5143412\ttotal: 1m 33s\tremaining: 2.25s\n",
      "7812:\tlearn: 0.5143198\ttotal: 1m 33s\tremaining: 2.24s\n",
      "7813:\tlearn: 0.5143077\ttotal: 1m 33s\tremaining: 2.23s\n",
      "7814:\tlearn: 0.5142932\ttotal: 1m 33s\tremaining: 2.21s\n",
      "7815:\tlearn: 0.5142795\ttotal: 1m 33s\tremaining: 2.2s\n",
      "7816:\tlearn: 0.5142673\ttotal: 1m 33s\tremaining: 2.19s\n",
      "7817:\tlearn: 0.5142571\ttotal: 1m 33s\tremaining: 2.18s\n",
      "7818:\tlearn: 0.5142351\ttotal: 1m 33s\tremaining: 2.17s\n",
      "7819:\tlearn: 0.5142141\ttotal: 1m 33s\tremaining: 2.15s\n",
      "7820:\tlearn: 0.5141888\ttotal: 1m 33s\tremaining: 2.14s\n",
      "7821:\tlearn: 0.5141550\ttotal: 1m 33s\tremaining: 2.13s\n",
      "7822:\tlearn: 0.5141305\ttotal: 1m 33s\tremaining: 2.12s\n",
      "7823:\tlearn: 0.5141152\ttotal: 1m 33s\tremaining: 2.11s\n",
      "7824:\tlearn: 0.5141047\ttotal: 1m 33s\tremaining: 2.1s\n",
      "7825:\tlearn: 0.5140718\ttotal: 1m 33s\tremaining: 2.08s\n",
      "7826:\tlearn: 0.5140466\ttotal: 1m 33s\tremaining: 2.07s\n",
      "7827:\tlearn: 0.5140316\ttotal: 1m 33s\tremaining: 2.06s\n",
      "7828:\tlearn: 0.5140050\ttotal: 1m 33s\tremaining: 2.05s\n",
      "7829:\tlearn: 0.5139739\ttotal: 1m 33s\tremaining: 2.04s\n",
      "7830:\tlearn: 0.5139585\ttotal: 1m 33s\tremaining: 2.02s\n",
      "7831:\tlearn: 0.5139268\ttotal: 1m 33s\tremaining: 2.01s\n",
      "7832:\tlearn: 0.5139075\ttotal: 1m 33s\tremaining: 2s\n",
      "7833:\tlearn: 0.5138872\ttotal: 1m 33s\tremaining: 1.99s\n",
      "7834:\tlearn: 0.5138742\ttotal: 1m 33s\tremaining: 1.98s\n",
      "7835:\tlearn: 0.5138687\ttotal: 1m 33s\tremaining: 1.96s\n",
      "7836:\tlearn: 0.5138424\ttotal: 1m 33s\tremaining: 1.95s\n",
      "7837:\tlearn: 0.5138012\ttotal: 1m 33s\tremaining: 1.94s\n",
      "7838:\tlearn: 0.5137728\ttotal: 1m 33s\tremaining: 1.93s\n",
      "7839:\tlearn: 0.5137521\ttotal: 1m 33s\tremaining: 1.92s\n",
      "7840:\tlearn: 0.5137317\ttotal: 1m 33s\tremaining: 1.9s\n",
      "7841:\tlearn: 0.5136979\ttotal: 1m 33s\tremaining: 1.89s\n",
      "7842:\tlearn: 0.5136751\ttotal: 1m 33s\tremaining: 1.88s\n",
      "7843:\tlearn: 0.5136314\ttotal: 1m 33s\tremaining: 1.87s\n",
      "7844:\tlearn: 0.5136078\ttotal: 1m 33s\tremaining: 1.86s\n",
      "7845:\tlearn: 0.5135688\ttotal: 1m 34s\tremaining: 1.84s\n",
      "7846:\tlearn: 0.5135413\ttotal: 1m 34s\tremaining: 1.83s\n",
      "7847:\tlearn: 0.5135265\ttotal: 1m 34s\tremaining: 1.82s\n",
      "7848:\tlearn: 0.5134982\ttotal: 1m 34s\tremaining: 1.81s\n",
      "7849:\tlearn: 0.5134655\ttotal: 1m 34s\tremaining: 1.8s\n",
      "7850:\tlearn: 0.5134429\ttotal: 1m 34s\tremaining: 1.78s\n",
      "7851:\tlearn: 0.5134314\ttotal: 1m 34s\tremaining: 1.77s\n",
      "7852:\tlearn: 0.5134054\ttotal: 1m 34s\tremaining: 1.76s\n",
      "7853:\tlearn: 0.5133949\ttotal: 1m 34s\tremaining: 1.75s\n",
      "7854:\tlearn: 0.5133871\ttotal: 1m 34s\tremaining: 1.74s\n",
      "7855:\tlearn: 0.5133475\ttotal: 1m 34s\tremaining: 1.73s\n",
      "7856:\tlearn: 0.5133196\ttotal: 1m 34s\tremaining: 1.71s\n",
      "7857:\tlearn: 0.5133034\ttotal: 1m 34s\tremaining: 1.7s\n",
      "7858:\tlearn: 0.5132800\ttotal: 1m 34s\tremaining: 1.69s\n",
      "7859:\tlearn: 0.5132633\ttotal: 1m 34s\tremaining: 1.68s\n",
      "7860:\tlearn: 0.5132405\ttotal: 1m 34s\tremaining: 1.67s\n",
      "7861:\tlearn: 0.5132164\ttotal: 1m 34s\tremaining: 1.65s\n",
      "7862:\tlearn: 0.5131777\ttotal: 1m 34s\tremaining: 1.64s\n",
      "7863:\tlearn: 0.5131499\ttotal: 1m 34s\tremaining: 1.63s\n",
      "7864:\tlearn: 0.5131130\ttotal: 1m 34s\tremaining: 1.62s\n",
      "7865:\tlearn: 0.5130966\ttotal: 1m 34s\tremaining: 1.6s\n",
      "7866:\tlearn: 0.5130786\ttotal: 1m 34s\tremaining: 1.59s\n",
      "7867:\tlearn: 0.5130698\ttotal: 1m 34s\tremaining: 1.58s\n",
      "7868:\tlearn: 0.5130622\ttotal: 1m 34s\tremaining: 1.57s\n",
      "7869:\tlearn: 0.5130472\ttotal: 1m 34s\tremaining: 1.56s\n",
      "7870:\tlearn: 0.5130378\ttotal: 1m 34s\tremaining: 1.54s\n",
      "7871:\tlearn: 0.5130085\ttotal: 1m 34s\tremaining: 1.53s\n",
      "7872:\tlearn: 0.5129916\ttotal: 1m 34s\tremaining: 1.52s\n",
      "7873:\tlearn: 0.5129823\ttotal: 1m 34s\tremaining: 1.51s\n",
      "7874:\tlearn: 0.5129681\ttotal: 1m 34s\tremaining: 1.5s\n",
      "7875:\tlearn: 0.5129409\ttotal: 1m 34s\tremaining: 1.49s\n",
      "7876:\tlearn: 0.5129303\ttotal: 1m 34s\tremaining: 1.47s\n",
      "7877:\tlearn: 0.5129074\ttotal: 1m 34s\tremaining: 1.46s\n",
      "7878:\tlearn: 0.5128877\ttotal: 1m 34s\tremaining: 1.45s\n",
      "7879:\tlearn: 0.5128717\ttotal: 1m 34s\tremaining: 1.44s\n",
      "7880:\tlearn: 0.5128294\ttotal: 1m 34s\tremaining: 1.43s\n",
      "7881:\tlearn: 0.5127982\ttotal: 1m 34s\tremaining: 1.41s\n",
      "7882:\tlearn: 0.5127680\ttotal: 1m 34s\tremaining: 1.4s\n",
      "7883:\tlearn: 0.5127485\ttotal: 1m 34s\tremaining: 1.39s\n",
      "7884:\tlearn: 0.5127208\ttotal: 1m 34s\tremaining: 1.38s\n",
      "7885:\tlearn: 0.5126951\ttotal: 1m 34s\tremaining: 1.37s\n",
      "7886:\tlearn: 0.5126744\ttotal: 1m 34s\tremaining: 1.35s\n",
      "7887:\tlearn: 0.5126523\ttotal: 1m 34s\tremaining: 1.34s\n",
      "7888:\tlearn: 0.5126231\ttotal: 1m 34s\tremaining: 1.33s\n",
      "7889:\tlearn: 0.5126077\ttotal: 1m 34s\tremaining: 1.32s\n",
      "7890:\tlearn: 0.5125911\ttotal: 1m 34s\tremaining: 1.31s\n",
      "7891:\tlearn: 0.5125773\ttotal: 1m 34s\tremaining: 1.29s\n",
      "7892:\tlearn: 0.5125579\ttotal: 1m 34s\tremaining: 1.28s\n",
      "7893:\tlearn: 0.5125433\ttotal: 1m 34s\tremaining: 1.27s\n",
      "7894:\tlearn: 0.5125356\ttotal: 1m 34s\tremaining: 1.26s\n",
      "7895:\tlearn: 0.5125083\ttotal: 1m 34s\tremaining: 1.25s\n",
      "7896:\tlearn: 0.5124824\ttotal: 1m 34s\tremaining: 1.23s\n",
      "7897:\tlearn: 0.5124657\ttotal: 1m 34s\tremaining: 1.22s\n",
      "7898:\tlearn: 0.5124169\ttotal: 1m 34s\tremaining: 1.21s\n",
      "7899:\tlearn: 0.5123925\ttotal: 1m 34s\tremaining: 1.2s\n",
      "7900:\tlearn: 0.5123831\ttotal: 1m 34s\tremaining: 1.19s\n",
      "7901:\tlearn: 0.5123478\ttotal: 1m 34s\tremaining: 1.17s\n",
      "7902:\tlearn: 0.5123343\ttotal: 1m 34s\tremaining: 1.16s\n",
      "7903:\tlearn: 0.5122913\ttotal: 1m 34s\tremaining: 1.15s\n",
      "7904:\tlearn: 0.5122866\ttotal: 1m 34s\tremaining: 1.14s\n",
      "7905:\tlearn: 0.5122586\ttotal: 1m 34s\tremaining: 1.13s\n",
      "7906:\tlearn: 0.5122310\ttotal: 1m 34s\tremaining: 1.11s\n",
      "7907:\tlearn: 0.5122224\ttotal: 1m 34s\tremaining: 1.1s\n",
      "7908:\tlearn: 0.5122027\ttotal: 1m 34s\tremaining: 1.09s\n",
      "7909:\tlearn: 0.5121616\ttotal: 1m 34s\tremaining: 1.08s\n",
      "7910:\tlearn: 0.5121335\ttotal: 1m 34s\tremaining: 1.07s\n",
      "7911:\tlearn: 0.5121121\ttotal: 1m 34s\tremaining: 1.05s\n",
      "7912:\tlearn: 0.5121022\ttotal: 1m 34s\tremaining: 1.04s\n",
      "7913:\tlearn: 0.5120644\ttotal: 1m 34s\tremaining: 1.03s\n",
      "7914:\tlearn: 0.5120362\ttotal: 1m 34s\tremaining: 1.02s\n",
      "7915:\tlearn: 0.5120003\ttotal: 1m 34s\tremaining: 1.01s\n",
      "7916:\tlearn: 0.5119788\ttotal: 1m 34s\tremaining: 995ms\n",
      "7917:\tlearn: 0.5119604\ttotal: 1m 34s\tremaining: 983ms\n",
      "7918:\tlearn: 0.5119408\ttotal: 1m 34s\tremaining: 971ms\n",
      "7919:\tlearn: 0.5119127\ttotal: 1m 34s\tremaining: 959ms\n",
      "7920:\tlearn: 0.5118977\ttotal: 1m 34s\tremaining: 947ms\n",
      "7921:\tlearn: 0.5118801\ttotal: 1m 35s\tremaining: 935ms\n",
      "7922:\tlearn: 0.5118510\ttotal: 1m 35s\tremaining: 923ms\n",
      "7923:\tlearn: 0.5118387\ttotal: 1m 35s\tremaining: 912ms\n",
      "7924:\tlearn: 0.5118207\ttotal: 1m 35s\tremaining: 900ms\n",
      "7925:\tlearn: 0.5117873\ttotal: 1m 35s\tremaining: 888ms\n",
      "7926:\tlearn: 0.5117743\ttotal: 1m 35s\tremaining: 876ms\n",
      "7927:\tlearn: 0.5117580\ttotal: 1m 35s\tremaining: 864ms\n",
      "7928:\tlearn: 0.5117394\ttotal: 1m 35s\tremaining: 852ms\n",
      "7929:\tlearn: 0.5117126\ttotal: 1m 35s\tremaining: 840ms\n",
      "7930:\tlearn: 0.5117001\ttotal: 1m 35s\tremaining: 828ms\n",
      "7931:\tlearn: 0.5116768\ttotal: 1m 35s\tremaining: 816ms\n",
      "7932:\tlearn: 0.5116477\ttotal: 1m 35s\tremaining: 804ms\n",
      "7933:\tlearn: 0.5116233\ttotal: 1m 35s\tremaining: 792ms\n",
      "7934:\tlearn: 0.5116012\ttotal: 1m 35s\tremaining: 780ms\n",
      "7935:\tlearn: 0.5115844\ttotal: 1m 35s\tremaining: 768ms\n",
      "7936:\tlearn: 0.5115657\ttotal: 1m 35s\tremaining: 756ms\n",
      "7937:\tlearn: 0.5115440\ttotal: 1m 35s\tremaining: 744ms\n",
      "7938:\tlearn: 0.5115115\ttotal: 1m 35s\tremaining: 732ms\n",
      "7939:\tlearn: 0.5114880\ttotal: 1m 35s\tremaining: 720ms\n",
      "7940:\tlearn: 0.5114717\ttotal: 1m 35s\tremaining: 708ms\n",
      "7941:\tlearn: 0.5114554\ttotal: 1m 35s\tremaining: 696ms\n",
      "7942:\tlearn: 0.5114386\ttotal: 1m 35s\tremaining: 684ms\n",
      "7943:\tlearn: 0.5114273\ttotal: 1m 35s\tremaining: 672ms\n",
      "7944:\tlearn: 0.5113876\ttotal: 1m 35s\tremaining: 660ms\n",
      "7945:\tlearn: 0.5113465\ttotal: 1m 35s\tremaining: 648ms\n",
      "7946:\tlearn: 0.5113331\ttotal: 1m 35s\tremaining: 636ms\n",
      "7947:\tlearn: 0.5113186\ttotal: 1m 35s\tremaining: 624ms\n",
      "7948:\tlearn: 0.5113043\ttotal: 1m 35s\tremaining: 612ms\n",
      "7949:\tlearn: 0.5112756\ttotal: 1m 35s\tremaining: 600ms\n",
      "7950:\tlearn: 0.5112625\ttotal: 1m 35s\tremaining: 588ms\n",
      "7951:\tlearn: 0.5112334\ttotal: 1m 35s\tremaining: 576ms\n",
      "7952:\tlearn: 0.5112083\ttotal: 1m 35s\tremaining: 564ms\n",
      "7953:\tlearn: 0.5111929\ttotal: 1m 35s\tremaining: 552ms\n",
      "7954:\tlearn: 0.5111772\ttotal: 1m 35s\tremaining: 540ms\n",
      "7955:\tlearn: 0.5111606\ttotal: 1m 35s\tremaining: 528ms\n",
      "7956:\tlearn: 0.5111121\ttotal: 1m 35s\tremaining: 516ms\n",
      "7957:\tlearn: 0.5110898\ttotal: 1m 35s\tremaining: 504ms\n",
      "7958:\tlearn: 0.5110642\ttotal: 1m 35s\tremaining: 492ms\n",
      "7959:\tlearn: 0.5110462\ttotal: 1m 35s\tremaining: 480ms\n",
      "7960:\tlearn: 0.5110329\ttotal: 1m 35s\tremaining: 468ms\n",
      "7961:\tlearn: 0.5110239\ttotal: 1m 35s\tremaining: 456ms\n",
      "7962:\tlearn: 0.5110013\ttotal: 1m 35s\tremaining: 444ms\n",
      "7963:\tlearn: 0.5109764\ttotal: 1m 35s\tremaining: 432ms\n",
      "7964:\tlearn: 0.5109626\ttotal: 1m 35s\tremaining: 420ms\n",
      "7965:\tlearn: 0.5109474\ttotal: 1m 35s\tremaining: 408ms\n",
      "7966:\tlearn: 0.5109311\ttotal: 1m 35s\tremaining: 396ms\n",
      "7967:\tlearn: 0.5109146\ttotal: 1m 35s\tremaining: 384ms\n",
      "7968:\tlearn: 0.5108917\ttotal: 1m 35s\tremaining: 372ms\n",
      "7969:\tlearn: 0.5108721\ttotal: 1m 35s\tremaining: 360ms\n",
      "7970:\tlearn: 0.5108596\ttotal: 1m 35s\tremaining: 348ms\n",
      "7971:\tlearn: 0.5108402\ttotal: 1m 35s\tremaining: 336ms\n",
      "7972:\tlearn: 0.5108244\ttotal: 1m 35s\tremaining: 324ms\n",
      "7973:\tlearn: 0.5108100\ttotal: 1m 35s\tremaining: 312ms\n",
      "7974:\tlearn: 0.5107940\ttotal: 1m 35s\tremaining: 300ms\n",
      "7975:\tlearn: 0.5107808\ttotal: 1m 35s\tremaining: 288ms\n",
      "7976:\tlearn: 0.5107424\ttotal: 1m 35s\tremaining: 276ms\n",
      "7977:\tlearn: 0.5107301\ttotal: 1m 35s\tremaining: 264ms\n",
      "7978:\tlearn: 0.5106984\ttotal: 1m 35s\tremaining: 252ms\n",
      "7979:\tlearn: 0.5106689\ttotal: 1m 35s\tremaining: 240ms\n",
      "7980:\tlearn: 0.5106567\ttotal: 1m 35s\tremaining: 228ms\n",
      "7981:\tlearn: 0.5106432\ttotal: 1m 35s\tremaining: 216ms\n",
      "7982:\tlearn: 0.5106294\ttotal: 1m 35s\tremaining: 204ms\n",
      "7983:\tlearn: 0.5106089\ttotal: 1m 35s\tremaining: 192ms\n",
      "7984:\tlearn: 0.5105847\ttotal: 1m 35s\tremaining: 180ms\n",
      "7985:\tlearn: 0.5105505\ttotal: 1m 35s\tremaining: 168ms\n",
      "7986:\tlearn: 0.5105318\ttotal: 1m 35s\tremaining: 156ms\n",
      "7987:\tlearn: 0.5105158\ttotal: 1m 35s\tremaining: 144ms\n",
      "7988:\tlearn: 0.5104922\ttotal: 1m 35s\tremaining: 132ms\n",
      "7989:\tlearn: 0.5104793\ttotal: 1m 35s\tremaining: 120ms\n",
      "7990:\tlearn: 0.5104581\ttotal: 1m 35s\tremaining: 108ms\n",
      "7991:\tlearn: 0.5104346\ttotal: 1m 35s\tremaining: 96ms\n",
      "7992:\tlearn: 0.5104160\ttotal: 1m 35s\tremaining: 84ms\n",
      "7993:\tlearn: 0.5103984\ttotal: 1m 35s\tremaining: 72ms\n",
      "7994:\tlearn: 0.5103921\ttotal: 1m 35s\tremaining: 60ms\n",
      "7995:\tlearn: 0.5103679\ttotal: 1m 35s\tremaining: 48ms\n",
      "7996:\tlearn: 0.5103567\ttotal: 1m 35s\tremaining: 36ms\n",
      "7997:\tlearn: 0.5103375\ttotal: 1m 35s\tremaining: 24ms\n",
      "7998:\tlearn: 0.5103096\ttotal: 1m 35s\tremaining: 12ms\n",
      "7999:\tlearn: 0.5102860\ttotal: 1m 35s\tremaining: 0us\n",
      "Best Score :  -0.752887791543842\n",
      "Best Params : \n",
      " {'grow_policy': 'Depthwise', 'l2_leaf_reg': 9.847870133539244, 'learning_rate': 0.01, 'loss_function': 'MultiClass', 'max_depth': 7, 'n_estimators': 8000, 'random_seed': 42, 'task_type': 'GPU', 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat = CatBoostClassifier()\n",
    "\n",
    "cat_param_grid = {\n",
    "    \"verbose\" : [0],\n",
    "    \"task_type\" : [\"GPU\"],\n",
    "    \"l2_leaf_reg\" : [9.847870133539244],\n",
    "    \"loss_function\" : [\"MultiClass\"],\n",
    "    \"random_seed\" : [42],\n",
    "    \"n_estimators\" : [8000],\n",
    "    \"learning_rate\" : [0.01],\n",
    "    \"grow_policy\" : [\"Depthwise\"],\n",
    "    \"max_depth\" : [7]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    cat, cat_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_cat = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best Params : \\n\", gs.best_params_)"
   ]
  },
  {
   "source": [
    "#### 3-1-4-1. CatBoost (without GridSearchCV)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    task_type=\"GPU\",\n",
    "    l2_leaf_reg=9.847870133539244,\n",
    "    loss_function=\"MultiClass\",\n",
    "    random_seed=42,\n",
    "    n_estimators=8000,\n",
    "    learning_rate=0.01,\n",
    "    grow_policy=\"Depthwise\",\n",
    "    max_depth=7\n",
    ")\n",
    "\n",
    "best_cat = cat.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "### 3-1-5. HistGradientBoostingClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=19, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.9min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.8min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=21, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "[CV] END l2_regularization=1.766059063693552, learning_rate=0.01, loss=categorical_crossentropy, max_depth=23, max_iter=500, random_state=42, scoring=neg_log_loss; total time= 1.7min\n",
      "Best Score :  -0.7768888876762893\n",
      "Best params : \n",
      " {'l2_regularization': 1.766059063693552, 'learning_rate': 0.01, 'loss': 'categorical_crossentropy', 'max_depth': 21, 'max_iter': 500, 'random_state': 42, 'scoring': 'neg_log_loss'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hist = HistGradientBoostingClassifier()\n",
    "\n",
    "hist_param_grid = {\n",
    "    \"loss\" : [\"categorical_crossentropy\"],\n",
    "    \"learning_rate\" : [0.01],\n",
    "    \"max_iter\" : [500],\n",
    "    \"max_depth\" : [21],\n",
    "    \"scoring\" : [\"neg_log_loss\"],\n",
    "    \"random_state\" : [42],\n",
    "    \"l2_regularization\" : [1.766059063693552]   \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    hist, hist_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_hist = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best params : \\n\", gs.best_params_)"
   ]
  },
  {
   "source": [
    "#### 3-1-5-1. HistGradientBoostingClassifier (without GridSearchCV)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hist = HistGradientBoostingClassifier(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    learning_rate=0.01,\n",
    "    max_iter=500,\n",
    "    max_depth=9,\n",
    "    scoring=\"neg_log_loss\",\n",
    "    l2_regularization=1.766059063693552\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "best_hist = hist.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## 3-2. Stacking models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_stacking_data(model, X_train_n, y_train_n, X_test_n, n_folds=5):\n",
    "    kfold = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
    "    print(\"model : \", model.__class__.__name__)\n",
    "\n",
    "    for cnt, (train_idx, valid_idx) in enumerate(kfold.split(X_train_n,y_train_n)):\n",
    "        print(f\"Fold : {cnt+1}\")\n",
    "        X_train_ = X_train_n.iloc[train_idx]\n",
    "        y_train_ = y_train_n.iloc[train_idx]\n",
    "        X_validation = X_train_n.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train_, y_train_)\n",
    "\n",
    "        train_fold_pred[valid_idx, :] = model.predict(X_validation).reshape(-1, 1)\n",
    "\n",
    "        test_pred[:, cnt] = model.predict(X_test_n)\n",
    "    \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "source": [
    "### 3-2-1. Validation step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model :  RandomForestClassifier\n",
      "Fold : 1\n",
      "Fold : 2\n",
      "Fold : 3\n",
      "Fold : 4\n",
      "Fold : 5\n",
      "model :  LGBMClassifier\n",
      "Fold : 1\n",
      "Fold : 2\n",
      "Fold : 3\n",
      "Fold : 4\n",
      "Fold : 5\n",
      "model :  XGBClassifier\n",
      "Fold : 1\n",
      "Fold : 2\n",
      "Fold : 3\n",
      "Fold : 4\n",
      "Fold : 5\n",
      "model :  HistGradientBoostingClassifier\n",
      "Fold : 1\n",
      "Fold : 2\n",
      "Fold : 3\n",
      "Fold : 4\n",
      "Fold : 5\n"
     ]
    }
   ],
   "source": [
    "forest_train, forest_val = get_stacking_data(best_forest, X_train, y_train, X_val)\n",
    "lgb_train, lgb_val = get_stacking_data(best_lgb, X_train, y_train, X_val)\n",
    "xgb_train, xgb_val = get_stacking_data(best_xgb, X_train, y_train, X_val)\n",
    "#cat_train, cat_val = get_stacking_data(best_cat, X_train, y_train, X_val)\n",
    "hist_train, hist_val = get_stacking_data(best_hist, X_train, y_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_X_train = np.concatenate((forest_train, lgb_train, xgb_train, hist_train), axis=1)\n",
    "stack_X_val = np.concatenate((forest_val, lgb_val, xgb_val, hist_val), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2., 2., 2., 2.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.],\n",
       "       ...,\n",
       "       [1., 2., 2., 2.],\n",
       "       [2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "stack_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=3, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=1100, random_state=42; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.6s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.4s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.8s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.9s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=3, n_estimators=2000, random_state=42; total time=   6.7s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.8s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   4.0s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   4.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   3.9s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=1100, random_state=42; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=5, n_estimators=2000, random_state=42; total time=   7.2s\n",
      "Best Score :  -0.7728585318873012\n",
      "Best Params :  {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1100, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest_param_grid = {\n",
    "    \"max_depth\" : [3, 5],\n",
    "    \"n_estimators\" : [1100, 2000],\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"random_state\" : [42]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    forest, forest_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(stack_X_train, y_train)\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best Params : \", gs.best_params_)\n",
    "\n",
    "best_model.fit(stack_X_train, y_train)\n",
    "\n",
    "stack_pred_val = best_model.predict_proba(stack_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.5s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.001, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.6s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "[CV] END learning_rate=0.1, max_depth=9, n_estimators=700, random_state=42; total time=   1.4s\n",
      "Best Score :  -0.7731491214717143\n",
      "Best Params :  {'learning_rate': 0.01, 'max_depth': 9, 'n_estimators': 700, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "\n",
    "lgb_param_grid = {\n",
    "    \"n_estimators\" : [700],\n",
    "    \"learning_rate\" : [0.001, 0.01, 0.1],\n",
    "    \"max_depth\" : [9],\n",
    "    \"random_state\" : [42]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    lgb, lgb_param_grid,\n",
    "    cv=k_fold, scoring=\"neg_log_loss\", verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(stack_X_train, y_train)\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "print(\"Best Score : \", gs.best_score_)\n",
    "print(\"Best Params : \", gs.best_params_)\n",
    "\n",
    "best_model.fit(stack_X_train, y_train)\n",
    "\n",
    "stack_pred_val = best_model.predict_proba(stack_X_val)"
   ]
  },
  {
   "source": [
    "### 3-2-2. test step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_train, forest_test = get_stacking_data(best_forest, X_train, y_train, X_test)\n",
    "ada_train, ada_test = get_stacking_data(best_ada, X_train, y_train, X_test)\n",
    "xgb_train, xgb_test = get_stacking_data(best_xgb, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_X_train = np.concatenate((forest_train, ada_train, xgb_train), axis=1)\n",
    "stack_X_test = np.concatenate((forest_test, ata_test, xgb_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(stack_X_train, y_train)\n",
    "\n",
    "stack_pred_test = best_model.predict_proba(stack_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_pred_test"
   ]
  },
  {
   "source": [
    "# 4. Evaluating : logloss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "logloss = log_loss(to_categorical(y_val), stack_pred_val)\n",
    "print(logloss)"
   ]
  },
  {
   "source": [
    "# 5. Submission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file_dir = \"../result_file/performace_result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_pred_test = pd.DataFrame(stack_pred_test)\n",
    "stack_pred_test.columns = ['0', '1', '2']\n",
    "\n",
    "submission['0'] = stack_pred_test['0']\n",
    "submission['1'] = stack_pred_test['1']\n",
    "submission['2'] = stack_pred_test['2']\n",
    "\n",
    "submission.to_csv(os.path.join(submit_file_dir, \"result_stacking.csv\"), index=False)"
   ]
  }
 ]
}