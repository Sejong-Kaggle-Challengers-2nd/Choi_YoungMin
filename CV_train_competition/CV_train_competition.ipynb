{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "million-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-growing",
   "metadata": {},
   "source": [
    "# ResNet + Semi-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "downtown-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchcontrib\n",
    "\n",
    "# 이미지 augmentation(이미지 data 증강)을 지원해주는 일종의 라이브러리\n",
    "# 어떤 논문에 따르면 torchvision이나, keras, imgaug보다 빠른 속도를 지원함.\n",
    "import albumentations as A\n",
    "from iterstrat import ml_stratifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "other-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduction을 위한 Seed 고정\n",
    "\n",
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "professional-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 28\n",
    "MEAN = 0.143\n",
    "STD = 0.254\n",
    "NUM_CALSSES = 10\n",
    "PIXEL_COLS = [str(i) for i in range(784)]\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-illinois",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legitimate-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../../kaggle_data/CV_train_competition\")\n",
    "df = pd.read_csv(DATA_PATH/\"train.csv\") # Path()를 사용하여 PATH/(특정파일) 로 접근 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "retained-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤하게 몇개의 Data를 뽑고 싶을 때 -> df.sample() 함수 사용\n",
    "# df.sample(n=5) -> 5 개의 row를 랜덤하게 뽑아줌.\n",
    "# df.sample(frac=0.7) -> 전체 row의 70퍼센트를 뽑아온다.\n",
    "# df.sample(frac=1).reset_index(drop=Ture) -> 전체 데이터의 shuffling\n",
    "# reset_index -> 기존의 index가 아닌 새로운 indexing을 가능하게 함.\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civil-syria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 'Y'],\n",
       "       [9, 'C'],\n",
       "       [6, 'D'],\n",
       "       ...,\n",
       "       [8, 'H'],\n",
       "       [8, 'M'],\n",
       "       [7, 'A']], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[[\"digit\", \"letter\"]].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "residential-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# KFold -> target의 비율이 특정으로 몰린채로 잘려서 교차검증하면 문제가 생김\n",
    "# 이를 해결하기 위해 target에 속성값 개수를 동일하게 하게 가져가는 것이 필요\n",
    "# 그게 stratifiedKFold 임.\n",
    "kf = ml_stratifiers.MultilabelStratifiedKFold(n_splits=5)\n",
    "for fold, (train_, valid_) in enumerate(kf.split(df, y=y)) :\n",
    "    np.save(f\"./train_fold{fold}\", train_)\n",
    "    np.save(f\"./valid_fold{fold}\", valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "novel-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 subcalsses 들은 주어진 key로 data fetching을 지원할 때, __getitem__()를 overwrite 해야함.\n",
    "# 때에 따라 __len__()을 overwrite할 수 있다. -> 이는 Sampler 구현에 의한 Dataset의 크기와 DataLoader으 기본 옵션을 반환할 것이다.\n",
    "\n",
    "\n",
    "class EMNISTDataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, df, list_IDs, aug=None, label=True) :\n",
    "        self.list_IDs = list_IDs\n",
    "        self.label = label\n",
    "        \n",
    "        self.images = df[PIXEL_COLS].values\n",
    "        self.images = self.images.astype(np.uint8)\n",
    "        self.images = self.images.reshape(-1, SIZE, SIZE, 1)\n",
    "        \n",
    "        if label :\n",
    "            self.digits = df.digit.values\n",
    "            \n",
    "        if augs is None : # 별도의 augmentation 기법 적용이 없다면\n",
    "            # augmentatoin pipline을 정의하기 위해 Compose instance 생성하기\n",
    "            # Compose class의 argument로 적용하고자하는 augmentations 들을 list로 넘겨줘야함.\n",
    "            # Normalize -> 정규화된 augmentation 적용 인듯...?\n",
    "            self.augs = A.Compose(\n",
    "            [A.Normalize(MEAN, STD, max_pixel_value=255.0, always_apply=True,),]\n",
    "            )\n",
    "            \n",
    "        else : self.augs = augs\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, item) :\n",
    "        # getimage\n",
    "        index = self.list_IDs[item]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        # Augment image\n",
    "        # compose로 정의한 augmentation을 aug(image=imgae)와 같이 넘겨서 augmentation 진행\n",
    "        # augmented 한결과에서 \"image\" column의 결과를 가져옴\n",
    "        # 그것이 augmented 한 image임.\n",
    "        image = self.augs(image=image)[\"image\"]\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        image = image.permute(2, 0, 1) # 축을 바꿔주는 역할을 함.\n",
    "        # 0->2, 1->0, 2-> 1 로 차원을 변경해줌.\n",
    "        # color channel을 torch에서 먼저 처리하는게 아닐까..?\n",
    "        \n",
    "        # Get labels and return\n",
    "        if self.label :\n",
    "            digit = self.digit[index]\n",
    "            digit = torch.tensor(digit, dtype=torch.long)\n",
    "            return image, digit # label이 있는 train data의 경우 image와 label 모두 반환\n",
    "        else :\n",
    "            return image # label이 없는 test data의 경우 image data만 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-commons",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "integral-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(m) :\n",
    "    # getattr ; object에 존재하는 속성의 값을 가져옴.\n",
    "    # getattr(object, 속성의 이름, 그 속성의 기본값)\n",
    "    if getattr(m, \"bias\", None) is not None :\n",
    "        nn.init.constant_(m.bias, 0) # Tensor의 값을 특정 상수로 초기화함.\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)) : # 어떤 object가 특정 형식인지 T/F 판단\n",
    "        nn.init.kaiming_normal_(m.weight) # weight 초기화 방식 중의 하나\n",
    "    for l in m.children() :\n",
    "        init.cnn(l) #해당 module의 children들을 모두 cnn 초기화함....?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-authentication",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "starting-leadership",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-ca88d2b24fc9>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ca88d2b24fc9>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    class BasicBlock(nn.Module) :\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1) :\n",
    "    return nn.Conv2d(\n",
    "        in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "    )\n",
    "\n",
    "class BasicBlock(nn.Module) :\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1) :\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_planes,\n",
    "                    self.expansion * planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion * planes),\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    \"\"\"Pre-activation version of the BasicBlock\"\"\"\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_planes,\n",
    "                    self.expansion * planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.conv1(x)\n",
    "        out = self.conv2(F.relu(self.bn2(x)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"Pre-activation version of the original Bottleneck module.\"\"\"\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_planes,\n",
    "                    self.expansion * planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion * planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = conv3x3(1, 64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1024 * block.expansion, num_classes)\n",
    "        init_cnn(self)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        avg_feats = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        max_feats = F.adaptive_max_pool2d(x, output_size=1)\n",
    "        x = torch.cat([avg_feats, max_feats], dim=1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(PreActBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-stevens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-brunei",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-prague",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-james",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-manhattan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-heart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-symbol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
